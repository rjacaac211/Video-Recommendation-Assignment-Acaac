{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from src.recommendation_engine.content_based import ContentBasedRecommender\n",
    "from src.recommendation_engine.collaborative import CollaborativeRecommender\n",
    "from src.recommendation_engine.hybrid import HybridRecommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading interactions data from data/processed/interaction_df.csv...\n",
      "Interactions DataFrame Loaded: (9781, 9) rows, columns: ['id', 'post_id', 'user_id', 'viewed_at', 'interaction_type', 'rating_percent', 'liked_at', 'inspired_at', 'rated_at']\n",
      "     id  post_id  user_id            viewed_at interaction_type  \\\n",
      "0  9447     1256        1  2024-09-24 13:33:57           viewed   \n",
      "1  9487     1253        1  2024-09-25 07:34:56           viewed   \n",
      "2  9488     1257        1  2024-09-25 07:36:46           viewed   \n",
      "3  9489     1258        1  2024-09-25 07:36:47           viewed   \n",
      "4  9502     1252        1  2024-09-26 15:09:11           viewed   \n",
      "\n",
      "   rating_percent liked_at inspired_at rated_at  \n",
      "0             NaN      NaN         NaN      NaN  \n",
      "1             NaN      NaN         NaN      NaN  \n",
      "2             NaN      NaN         NaN      NaN  \n",
      "3             NaN      NaN         NaN      NaN  \n",
      "4             NaN      NaN         NaN      NaN  \n",
      "Creating User-Post Interaction Matrix...\n",
      "User-Post Matrix Shape: (831, 835)\n",
      "User-Post Interaction Matrix (First Few Rows):\n",
      "post_id  11    12    13    14    15    16    17    19    23    26    ...  \\\n",
      "user_id                                                              ...   \n",
      "1         1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0  ...   \n",
      "5         1.0   0.0   0.0   1.0   1.0   1.0   0.0   1.0   1.0   0.0  ...   \n",
      "9         0.0   0.0   1.0   1.0   1.0   1.0   0.0   1.0   1.0   1.0  ...   \n",
      "16        1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
      "18        1.0   0.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0  ...   \n",
      "\n",
      "post_id  1631  1632  1633  1634  1636  1638  1640  1641  1644  1654  \n",
      "user_id                                                              \n",
      "1         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "5         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "9         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "16        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "18        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[5 rows x 835 columns]\n",
      "Computing Item-Item Similarity...\n",
      "Item-Item Similarity Matrix Shape: (835, 835)\n",
      "Generating hybrid recommendations for user: 1\n",
      "Post ID 1 not found in posts data.\n",
      "Generating recommendations for user_id: 1\n",
      "Top-400 Recommendations for user_id 1:\n",
      "     post_id       score\n",
      "0         82  123.161119\n",
      "1         85  113.963287\n",
      "2        837  104.530852\n",
      "3        722  104.102783\n",
      "4        658  103.941377\n",
      "..       ...         ...\n",
      "395     1035    2.137670\n",
      "396     1036    2.137670\n",
      "397     1037    2.137670\n",
      "398     1612    2.070642\n",
      "399     1175    2.045907\n",
      "\n",
      "[400 rows x 2 columns]\n",
      "Content-Based Recommendations: Empty DataFrame\n",
      "Columns: [post_id, score]\n",
      "Index: []\n",
      "Collaborative Recommendations:      post_id       score\n",
      "0         82  123.161119\n",
      "1         85  113.963287\n",
      "2        837  104.530852\n",
      "3        722  104.102783\n",
      "4        658  103.941377\n",
      "..       ...         ...\n",
      "395     1035    2.137670\n",
      "396     1036    2.137670\n",
      "397     1037    2.137670\n",
      "398     1612    2.070642\n",
      "399     1175    2.045907\n",
      "\n",
      "[400 rows x 2 columns]\n",
      "Final Hybrid Recommendations:     post_id  weighted_score\n",
      "7        82       86.212784\n",
      "8        85       79.774301\n",
      "139     837       73.171597\n",
      "119     722       72.871948\n",
      "106     658       72.758964\n",
      "..      ...             ...\n",
      "186     966        1.496369\n",
      "185     965        1.496369\n",
      "180     946        1.496369\n",
      "383    1612        1.449449\n",
      "291    1175        1.432135\n",
      "\n",
      "[400 rows x 2 columns]\n",
      "NaN values detected. Replacing NaN values with 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/Users/RJ/Career_Growth/Career Development/Job application/Internshala/AI Intern at Persist Ventures/Video-Recommendation-Assignment-Acaac/src/recommendation_engine/hybrid.py:45: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([content_df, collaborative_df], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Paths to your data files\n",
    "posts_csv_path = \"data/processed/all_posts_with_features.csv\"\n",
    "interactions_csv_path = \"data/processed/interaction_df.csv\"\n",
    "\n",
    "# Initialize the Content-Based and Collaborative recommenders\n",
    "content_recommender = ContentBasedRecommender(posts_csv_path)\n",
    "collaborative_recommender = CollaborativeRecommender(interactions_csv_path)\n",
    "\n",
    "# Instantiate the HybridRecommender using the previously created content-based and collaborative models\n",
    "hybrid_recommender = HybridRecommender(content_model=content_recommender, collaborative_model=collaborative_recommender, weight_content=0.3, weight_collaborative=0.7)\n",
    "\n",
    "# Select a valid user_id (you can choose any valid user from your dataset)\n",
    "user_id = 1\n",
    "\n",
    "top_n=400\n",
    "\n",
    "# Generate hybrid recommendations for the user\n",
    "recommendations_df = hybrid_recommender.recommend_hybrid(user_id, top_n=top_n)\n",
    "\n",
    "# Get the true ratings for the recommended posts\n",
    "interaction_df = pd.read_csv(interactions_csv_path)  # Load the interactions data\n",
    "\n",
    "# Extract the true ratings (ground truth) for the recommended posts\n",
    "true_ratings = interaction_df[interaction_df['post_id'].isin(recommendations_df['post_id'])]\n",
    "\n",
    "# Ensure the true ratings correspond to the recommended posts\n",
    "true_ratings = true_ratings.set_index('post_id').loc[recommendations_df['post_id']].reset_index()\n",
    "\n",
    "# Handle missing ratings (if any post in recommendations does not have a rating)\n",
    "missing_posts = recommendations_df[~recommendations_df['post_id'].isin(true_ratings['post_id'])]\n",
    "if not missing_posts.empty:\n",
    "    print(f\"Missing ratings for the following posts: {missing_posts['post_id'].values}\")\n",
    "    # You can choose to assign a default rating (e.g., 0 or the average rating)\n",
    "    true_ratings = pd.concat([true_ratings, missing_posts.assign(rating_percent=0)], ignore_index=True)\n",
    "\n",
    "# Now, limit the true_ratings to match the top N recommended posts (10 in this case)\n",
    "true_ratings = true_ratings.head(top_n)\n",
    "\n",
    "# Ensure the lengths of true_ratings and recommendations_df match\n",
    "# No need for assertion now, as we are slicing the data\n",
    "assert len(true_ratings) == len(recommendations_df), f\"Mismatch between true ratings ({len(true_ratings)}) and predicted ratings ({len(recommendations_df)})\"\n",
    "\n",
    "# Now, get the predicted ratings (the weighted score from the hybrid model)\n",
    "predicted_ratings = recommendations_df['weighted_score'].values\n",
    "true_ratings_values = true_ratings['rating_percent'].values\n",
    "\n",
    "# Check for NaN values in the true ratings and predicted ratings\n",
    "if np.any(np.isnan(true_ratings_values)) or np.any(np.isnan(predicted_ratings)):\n",
    "    print(\"NaN values detected. Replacing NaN values with 0.\")\n",
    "    \n",
    "    # Replace NaN values with 0 or any other default value\n",
    "    true_ratings_values = np.nan_to_num(true_ratings_values, nan=0)\n",
    "    predicted_ratings = np.nan_to_num(predicted_ratings, nan=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Model - Mean Absolute Error (MAE): 21.256244208555152\n",
      "Hybrid Model - Root Mean Square Error (RMSE): 28.302076514884284\n"
     ]
    }
   ],
   "source": [
    "# Compute MAE (Mean Absolute Error)\n",
    "mae = mean_absolute_error(true_ratings_values, predicted_ratings)\n",
    "print(f\"Hybrid Model - Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "# Compute RMSE (Root Mean Square Error)\n",
    "rmse = np.sqrt(mean_squared_error(true_ratings_values, predicted_ratings))\n",
    "print(f\"Hybrid Model - Root Mean Square Error (RMSE): {rmse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (vid_recom)",
   "language": "python",
   "name": "vid_recom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
